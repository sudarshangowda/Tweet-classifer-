{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    355\n",
      "1    293\n",
      "Name: Final_Migration_label, dtype: int64\n",
      "------------- METRICS --------------\n",
      "LOGISTIC REGRESSION\n",
      "score : 0.8641975308641975\n",
      "balanced accuracy : 0.864367816091954\n",
      "confusion matrix: \n",
      "      predicted_YES  predicted_NO\n",
      "YES             65            10\n",
      "NO              12            75\n",
      "f1score:  0.8552631578947368\n",
      "precision:  0.8441558441558441\n",
      "recall:  0.8666666666666667\n",
      "------------------------------------\n",
      "Multinomial NB\n",
      "score : 0.8271604938271605\n",
      "balanced accuracy : 0.8298850574712644\n",
      "confusion matrix: \n",
      "      predicted_YES  predicted_NO\n",
      "YES             65            10\n",
      "NO              18            69\n",
      "f1score:  0.8227848101265823\n",
      "precision:  0.7831325301204819\n",
      "recall:  0.8666666666666667\n",
      "------------------------------------\n",
      "DecisionTreeClassifier\n",
      "score : 0.8395061728395061\n",
      "balanced accuracy : 0.8358620689655172\n",
      "confusion matrix: \n",
      "      predicted_YES  predicted_NO\n",
      "YES             59            16\n",
      "NO              10            77\n",
      "f1score:  0.8194444444444444\n",
      "precision:  0.855072463768116\n",
      "recall:  0.7866666666666666\n",
      "------------------------------------\n",
      "RandomForestClassifier\n",
      "score : 0.8333333333333334\n",
      "balanced accuracy : 0.8319540229885057\n",
      "confusion matrix: \n",
      "      predicted_YES  predicted_NO\n",
      "YES             61            14\n",
      "NO              13            74\n",
      "f1score:  0.8187919463087249\n",
      "precision:  0.8243243243243243\n",
      "recall:  0.8133333333333334\n",
      "------------------------------------\n",
      "SVMClassifier\n",
      "score : 0.8271604938271605\n",
      "balanced accuracy : 0.824367816091954\n",
      "confusion matrix: \n",
      "      predicted_YES  predicted_NO\n",
      "YES             59            16\n",
      "NO              12            75\n",
      "f1score:  0.8082191780821917\n",
      "precision:  0.8309859154929577\n",
      "recall:  0.7866666666666666\n",
      "------------------------------------\n",
      "KNN Classifier\n",
      "score : 0.7345679012345679\n",
      "balanced accuracy : 0.7234482758620691\n",
      "confusion matrix: \n",
      "      predicted_YES  predicted_NO\n",
      "YES             43            32\n",
      "NO              11            76\n",
      "f1score:  0.6666666666666667\n",
      "precision:  0.7962962962962963\n",
      "recall:  0.5733333333333334\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\python\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import textblob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def get_feature_engineered_data():\n",
    "    inp_filename = \"./MigrationTweets.csv\"\n",
    "    out_filename = \"./MigrationData.csv\"\n",
    "\n",
    "    keyword_list = [\"refugeecrisis\", \"refugee\", \"refugeeswelcome\", \"referendum\", \"eu\",\n",
    "                    \"syrian\", \"syria\", \"UN\", \"syrian refugee\", \"migrant\", \"attack\", \"europe\", \"children\",\n",
    "                    \"state\", \"voters\", \"refugeesgr\", \"found\", \"invalid\", \"withrefugees\", \"germany\",\n",
    "                    \"isis\", \"accept\", \"nearly\", \"migrant\", \"immigr\"]\n",
    "    with \\\n",
    "            open(inp_filename,\n",
    "                 'r+',\n",
    "                 encoding=\"utf-8\") as inp, \\\n",
    "            open(out_filename,\n",
    "                 'w+',\n",
    "                 encoding=\"utf-8\") as out:\n",
    "        reader = csv.DictReader(inp)\n",
    "        my_fields = ['Text',\n",
    "                     'Final_Migration_label',\n",
    "                     'Similarity']\n",
    "\n",
    "        writer = csv.DictWriter(out, fieldnames=my_fields)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            # append 1st feature\n",
    "            sim = get_avg_cosine_similarity(row['tweet_text'], keyword_list)\n",
    "            writer.writerow({'Text': row['tweet_text'],\n",
    "                             'Final_Migration_label': row['migration_relevance'],\n",
    "                             'Similarity': sim\n",
    "                             })\n",
    "\n",
    "        return out_filename\n",
    "\n",
    "\n",
    "def preprocess_tweets(data):\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "    data['Text'].dropna(inplace=True)\n",
    "    for index, sentence in enumerate(data['Text']):\n",
    "        # removing html links\n",
    "        sentence = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', str(sentence))\n",
    "        # Removing Punctuations\n",
    "        sentence = re.sub(r'[?|!|\\'|\\’|\"|#|@|_|:|“|”|-|\"|-|-|<|>|{|}.|,|)|(|\\|/]', r'', sentence)\n",
    "        sentence = nltk.word_tokenize(sentence)\n",
    "        # Stemming and removing stopwords\n",
    "        words = [snow.stem(word) for word in sentence if word not in stopwords.words('english')]\n",
    "        data.loc[index, 'Text'] = (\" \".join(map(str, words)))\n",
    "    X = data['Text']\n",
    "    return data\n",
    "\n",
    "\n",
    "def main():\n",
    "    SEED = 4000\n",
    "    outfile_name = get_feature_engineered_data()\n",
    "    filename = \"./\" + outfile_name\n",
    "\n",
    "    dataf = pd.read_csv(filename)\n",
    "    df = preprocess_tweets(dataf)\n",
    "\n",
    "    df['Final_Migration_label'] = df['Final_Migration_label'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "    Text = df['Text']\n",
    "    Weight = df['Similarity'].fillna(0)\n",
    "    label = df['Final_Migration_label']\n",
    "\n",
    "    print(df.Final_Migration_label.value_counts())\n",
    "\n",
    "    dataf = pd.DataFrame(np.vstack([Text, Weight]).T, columns=['Text', 'Weight'])\n",
    "\n",
    "    df_train, df_test, y_train, y_test = train_test_split(dataf, label, random_state=SEED)\n",
    "\n",
    "    # Either Use Count Vectorizer - gives better results\n",
    "    vect = CountVectorizer()\n",
    "    vect.fit(df_train.Text)\n",
    "    X_text_train = vect.transform(df_train.Text)  # documents-terms matrix of training set\n",
    "    X_text_test = vect.transform(df_test.Text)\n",
    "\n",
    "    # Or use TFIDF n-grams\n",
    "    '''tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2, 3), max_features=5000)\n",
    "    tfidf_vect_ngram.fit(df_train.Text)\n",
    "    X_text_train = tfidf_vect_ngram.transform(df_train.Text)\n",
    "    X_text_test = tfidf_vect_ngram.transform(df_test.Text)'''\n",
    "\n",
    "    X_Weight_train = np.atleast_2d(df_train.Weight.astype(float)).T\n",
    "    X_Weight_test = np.atleast_2d(df_test.Weight.astype(float)).T\n",
    "\n",
    "    X_train = sp.hstack((X_text_train, X_Weight_train))\n",
    "    X_test = sp.hstack((X_text_test, X_Weight_test))\n",
    "\n",
    "    print(\"------------- METRICS --------------\")\n",
    "    print(\"LOGISTIC REGRESSION\")\n",
    "\n",
    "    log_model = LogisticRegression()\n",
    "\n",
    "    log_model = log_model.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred = log_model.predict(X_test)\n",
    "\n",
    "    sco = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    balanced_sco = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1score = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1, 0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['YES', 'NO'],\n",
    "                             columns=['predicted_YES', 'predicted_NO'])\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred)\n",
    "    print(\"score :\", sco)\n",
    "    print(\"balanced accuracy :\", balanced_sco)\n",
    "\n",
    "    print(\"confusion matrix: \\n\", confusion)\n",
    "    print(\"f1score: \", f1score)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"Multinomial NB\")\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    gnb = MultinomialNB()\n",
    "\n",
    "    gnb = gnb.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred = gnb.predict(X_test)\n",
    "\n",
    "    # sco = log_model.score( y_test , y_pred)\n",
    "\n",
    "    sco = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    balanced_sco = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1score = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1, 0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['YES', 'NO'],\n",
    "                             columns=['predicted_YES', 'predicted_NO'])\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred)\n",
    "    print(\"score :\", sco)\n",
    "    print(\"balanced accuracy :\", balanced_sco)\n",
    "\n",
    "    print(\"confusion matrix: \\n\", confusion)\n",
    "\n",
    "    print(\"f1score: \", f1score)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    print(\"DecisionTreeClassifier\")\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    dtc = DecisionTreeClassifier()\n",
    "\n",
    "    dtc = dtc.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred = dtc.predict(X_test)\n",
    "\n",
    "    # sco = log_model.score( y_test , y_pred)\n",
    "\n",
    "    sco = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    balanced_sco = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1score = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1, 0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['YES', 'NO'],\n",
    "                             columns=['predicted_YES', 'predicted_NO'])\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred)\n",
    "    print(\"score :\", sco)\n",
    "    print(\"balanced accuracy :\", balanced_sco)\n",
    "\n",
    "    print(\"confusion matrix: \\n\", confusion)\n",
    "\n",
    "    print(\"f1score: \", f1score)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    print(\"RandomForestClassifier\")\n",
    "    from sklearn import svm\n",
    "\n",
    "    clf_rf = RandomForestClassifier()\n",
    "\n",
    "    clf_rf = clf_rf.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "    # sco = log_model.score( y_test , y_pred)\n",
    "\n",
    "    sco = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    balanced_sco = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1score = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1, 0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['YES', 'NO'],\n",
    "                             columns=['predicted_YES', 'predicted_NO'])\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred)\n",
    "    print(\"score :\", sco)\n",
    "    print(\"balanced accuracy :\", balanced_sco)\n",
    "\n",
    "    print(\"confusion matrix: \\n\", confusion)\n",
    "\n",
    "    print(\"f1score: \", f1score)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    print(\"SVMClassifier\")\n",
    "\n",
    "    clf_rf = svm.SVC(kernel='linear')\n",
    "\n",
    "    clf_rf = clf_rf.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "    # sco = log_model.score( y_test , y_pred)\n",
    "\n",
    "    sco = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    balanced_sco = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1score = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1, 0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['YES', 'NO'],\n",
    "                             columns=['predicted_YES', 'predicted_NO'])\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred)\n",
    "    print(\"score :\", sco)\n",
    "    print(\"balanced accuracy :\", balanced_sco)\n",
    "\n",
    "    print(\"confusion matrix: \\n\", confusion)\n",
    "\n",
    "    print(\"f1score: \", f1score)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    print(\"KNN Classifier\")\n",
    "\n",
    "    clf_rf = KNeighborsClassifier()\n",
    "\n",
    "    clf_rf = clf_rf.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "    # sco = log_model.score( y_test , y_pred)\n",
    "\n",
    "    sco = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    balanced_sco = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1score = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1, 0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['YES', 'NO'],\n",
    "                             columns=['predicted_YES', 'predicted_NO'])\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred)\n",
    "    print(\"score :\", sco)\n",
    "    print(\"balanced accuracy :\", balanced_sco)\n",
    "\n",
    "    print(\"confusion matrix: \\n\", confusion)\n",
    "\n",
    "    print(\"f1score: \", f1score)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"------------------------------------\")\n",
    "    # --------------------------------\n",
    "\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "    vector1 = text_to_vector(text1)\n",
    "    vector2 = text_to_vector(text2)\n",
    "    return get_cosine(vector1, vector2)\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    WORD = re.compile(r'\\w+')\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([vec1[x] ** 2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def get_avg_cosine_similarity(data, keyword_list):\n",
    "    # Split the data into pairs\n",
    "\n",
    "    cosine_sim = 0.0\n",
    "\n",
    "    # Compute Average Content Similarity between pairs of tweets over a given range\n",
    "    # Summation of [similarity(one pair)/(total pairs in list)]\n",
    "    for keyword in keyword_list:\n",
    "        cosine_sim = cosine_sim + compute_similarity(data, keyword)\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "\n",
    "def get_text_based_features(tweet_text):\n",
    "    char_count = tweet_text.apply(len)\n",
    "    word_count = tweet_text.apply(lambda x: len(x.split()))\n",
    "    word_density = char_count / (word_count + 1)\n",
    "\n",
    "    noun_count = tweet_text.apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "    verb_count = tweet_text.apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "    adj_count = tweet_text.apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "    adv_count = tweet_text.apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "    pron_count = tweet_text.apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "\n",
    "    return word_density, noun_count, verb_count, adj_count, adv_count, pron_count\n",
    "\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    pos_family = {\n",
    "        'noun': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "        'pron': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
    "        'verb': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "        'adj': ['JJ', 'JJR', 'JJS'],\n",
    "        'adv': ['RB', 'RBR', 'RBS', 'WRB']\n",
    "    }\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
